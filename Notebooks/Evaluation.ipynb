{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !필수체크!\n",
    "* decode_env 를 잡고 있는지 확인\n",
    "* GPU 확인\n",
    "* Dataset PATH 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "\n",
    "print(\"현재 접속한 파이썬 가상환경은 {} 입니다. (decode_env 인지 확인할 것)\\n\".format(os.environ['CONDA_DEFAULT_ENV']))\n",
    "\n",
    "print(\"사용 가능한 GPU가 존재하는가? (True or False): \", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"사용 가능한 GPU의 수는 {} 개 입니다.\".format(torch.cuda.device_count()))\n",
    "    print(\"GPU 각각의 이름은 아래와 같습니다.\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU {}: {}\".format(i, torch.cuda.get_device_name(i)))\n",
    "else:\n",
    "    print(\"사용 가능한 GPU가 존재하지 않습니다. 혹은 GPU를 Pytorch가 찾지 못하고 있습니다.\")\n",
    "\n",
    "data_path = '/home/bbl/Dataset' # Dataset 폴더 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decode\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"DECODE version: {decode.utils.bookkeeping.decode_state()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODE - Evaluation\n",
    "In the following we show what DECODE provides in terms of evaluation.\n",
    "Please be advised to have a read of the Introduction notebook first.\n",
    "Evaluation always acts on two sets of emitters, mostly prediction and reference (i.e. ground truth). In the following we show some toy examples.\n",
    "\n",
    "## Evaluation Pipeline\n",
    "The evaluation workflow is almost always\n",
    "1. Definition of reference and candidate (=prediction) EmitterSet\n",
    "2. Matching of reference and candidate\n",
    "3. Evaluation of Detection and Localization Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy emittersets\n",
    "em_ref = decode.RandomEmitterSet(200, xy_unit='px', px_size=(100., 100.))\n",
    "em_ref.frame_ix = torch.randint_like(em_ref.frame_ix, low=0, high=20)\n",
    "\n",
    "em_pred = em_ref.clone()  # make independent copy\n",
    "em_pred = em_pred[torch.rand(len(em_pred)) <= 0.8]  # through away random subset of 20%\n",
    "em_pred.xyz += torch.randn_like(em_pred.xyz)  # wiggle coordinates a bit around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all emitters\n",
    "decode.plot.PlotCoordinates(pos_tar=em_ref.xyz_px, \n",
    "                            pos_out=em_pred.xyz_px).plot()\n",
    "plt.legend()\n",
    "plt.title('All Emitters')\n",
    "plt.show()\n",
    "\n",
    "# plot on a selected frame\n",
    "decode.plot.PlotCoordinates(pos_tar=em_ref[em_ref.frame_ix == 10].xyz_px, \n",
    "                            pos_out=em_pred[em_pred.frame_ix == 10].xyz_px).plot()\n",
    "plt.legend()\n",
    "plt.title('Single Frame')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching\n",
    "We perform matching like in the superres fight club (THE challenge). This means that one defines a search radius in which predictions are considered true positives. We have 1:1 matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = decode.evaluation.match_emittersets.GreedyHungarianMatching(match_dims=3, dist_lat=250, dist_ax=500.)  # always in nm\n",
    "\n",
    "tp, fp, fn, tp_match = matcher.forward(em_pred, em_ref)  # outputs true positives, false positives, false negatives, matched ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plot on a selected frame\n",
    "decode.plot.PlotCoordinates(pos_tar=tp_match[tp_match.frame_ix == 10].xyz_px, \n",
    "                            pos_out=tp[tp.frame_ix == 10].xyz_px,\n",
    "                            pos_ini=em_ref[em_ref.frame_ix == 10].xyz_px,\n",
    "                            match_lines=True).plot()\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Single Frame with matches connected by the lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation\n",
    "Below we perform the actual evaluation which is found in the convenience class `SMLMEvaluation`. Note that some of the evaluation metrices, i.e. the CRLB based ones, require special inputs which can not be computed from two emittersets alone. In Order to evaluate also those, you need to specify a PSF function, provide background estimates and calculate the CRLB:\n",
    "\n",
    "    emitter.populate_crlb(psf)\n",
    "    \n",
    "If these values are not present, a warning will be issued (`UserWarning: Non-Finite values encountered during fitting.`), it can be safely ignored though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = decode.evaluation.SMLMEvaluation()\n",
    "\n",
    "result = evaluator.forward(tp, fp, fn, tp_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance values\n",
    "result._asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more readable description of the metrices.\n",
    "evaluator.descriptors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('decode_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4709d8a620fc18ab853a695110ac6a3830da7a312123bd053a4d012ea0d962f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
